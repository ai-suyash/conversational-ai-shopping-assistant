{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f6f99b8-b483-4637-b5ad-7db18264f268",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e7c0cd3-17e9-4425-818e-a4169a0008fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Amazon Fashion reviews...\n",
      "Loading Amazon Fashion metadata...\n",
      "Reviews DataFrame preview:\n",
      "An error occurred during dataset loading: name 'df_reviews' is not defined\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Define dataset and configuration names\n",
    "dataset_name = \"McAuley-Lab/Amazon-Reviews-2023\"\n",
    "reviews_config = \"raw_review_Amazon_Fashion\"\n",
    "metadata_config = \"raw_meta_Amazon_Fashion\"\n",
    "\n",
    "try:\n",
    "    print(\"Loading Amazon Fashion reviews...\")\n",
    "    reviews_dataset = load_dataset(dataset_name, reviews_config, trust_remote_code=True)\n",
    "    df_reviews = reviews_dataset['full'].to_pandas()\n",
    "\n",
    "    print(\"Loading Amazon Fashion metadata...\")\n",
    "    metadata_dataset = load_dataset(dataset_name, metadata_config, trust_remote_code=True)\n",
    "    df_metadata = metadata_dataset['full'].to_pandas()\n",
    "    \n",
    "    print(\"Reviews DataFrame preview:\")\n",
    "    print(df_reviews.head())\n",
    "\n",
    "    print(\"\\nMetadata DataFrame preview:\")\n",
    "    print(df_metadata.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during dataset loading: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a5c83c2-9a87-43cc-8797-83f484890b27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_category</th>\n",
       "      <th>title</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>rating_number</th>\n",
       "      <th>features</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>images</th>\n",
       "      <th>videos</th>\n",
       "      <th>store</th>\n",
       "      <th>categories</th>\n",
       "      <th>details</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>bought_together</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMAZON FASHION</td>\n",
       "      <td>YUEDGE 5 Pairs Men's Moisture Control Cushione...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>16</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>{'hi_res': ['https://m.media-amazon.com/images...</td>\n",
       "      <td>{'title': [], 'url': [], 'user_id': []}</td>\n",
       "      <td>GiveGift</td>\n",
       "      <td>[]</td>\n",
       "      <td>{\"Package Dimensions\": \"10.31 x 8.5 x 1.73 inc...</td>\n",
       "      <td>B08BHN9PK5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMAZON FASHION</td>\n",
       "      <td>DouBCQ Women's Palazzo Lounge Wide Leg Casual ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7</td>\n",
       "      <td>[Drawstring closure, Machine Wash]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>{'hi_res': ['https://m.media-amazon.com/images...</td>\n",
       "      <td>{'title': [], 'url': [], 'user_id': []}</td>\n",
       "      <td>DouBCQ</td>\n",
       "      <td>[]</td>\n",
       "      <td>{\"Package Dimensions\": \"15 x 10.2 x 0.4 inches...</td>\n",
       "      <td>B08R39MRDW</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMAZON FASHION</td>\n",
       "      <td>Pastel by Vivienne Honey Vanilla Girls' Trapez...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>11</td>\n",
       "      <td>[Zipper closure, Hand Wash Only]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>{'hi_res': ['https://m.media-amazon.com/images...</td>\n",
       "      <td>{'title': [], 'url': [], 'user_id': []}</td>\n",
       "      <td>Pastel by Vivienne</td>\n",
       "      <td>[]</td>\n",
       "      <td>{\"Is Discontinued By Manufacturer\": \"No\", \"Pac...</td>\n",
       "      <td>B077KJHCJ4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMAZON FASHION</td>\n",
       "      <td>Mento Streamtail</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Thermoplastic Rubber sole, High Density Premi...</td>\n",
       "      <td>[Slip on the Women's Mento and you're ready to...</td>\n",
       "      <td>29.81</td>\n",
       "      <td>{'hi_res': ['https://m.media-amazon.com/images...</td>\n",
       "      <td>{'title': [], 'url': [], 'user_id': []}</td>\n",
       "      <td>Guy Harvey</td>\n",
       "      <td>[]</td>\n",
       "      <td>{\"Package Dimensions\": \"11.22 x 4.72 x 4.33 in...</td>\n",
       "      <td>B0811M2JG9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMAZON FASHION</td>\n",
       "      <td>RONNOX Women's 3-Pairs Bright Colored Calf Com...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3032</td>\n",
       "      <td>[Pull On closure, Size Guide: \"S\" fits calf 10...</td>\n",
       "      <td>[Ronnox Calf Sleeves - Allowing Your Body to P...</td>\n",
       "      <td>17.99</td>\n",
       "      <td>{'hi_res': ['https://m.media-amazon.com/images...</td>\n",
       "      <td>{'title': ['HONEST Review: RONNOX Women's 3-Pa...</td>\n",
       "      <td>RONNOX</td>\n",
       "      <td>[]</td>\n",
       "      <td>{\"Is Discontinued By Manufacturer\": \"No\", \"Pac...</td>\n",
       "      <td>B07SB2892S</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    main_category                                              title  \\\n",
       "0  AMAZON FASHION  YUEDGE 5 Pairs Men's Moisture Control Cushione...   \n",
       "1  AMAZON FASHION  DouBCQ Women's Palazzo Lounge Wide Leg Casual ...   \n",
       "2  AMAZON FASHION  Pastel by Vivienne Honey Vanilla Girls' Trapez...   \n",
       "3  AMAZON FASHION                                   Mento Streamtail   \n",
       "4  AMAZON FASHION  RONNOX Women's 3-Pairs Bright Colored Calf Com...   \n",
       "\n",
       "   average_rating  rating_number  \\\n",
       "0             4.6             16   \n",
       "1             4.1              7   \n",
       "2             4.3             11   \n",
       "3             2.0              1   \n",
       "4             4.3           3032   \n",
       "\n",
       "                                            features  \\\n",
       "0                                                 []   \n",
       "1                 [Drawstring closure, Machine Wash]   \n",
       "2                   [Zipper closure, Hand Wash Only]   \n",
       "3  [Thermoplastic Rubber sole, High Density Premi...   \n",
       "4  [Pull On closure, Size Guide: \"S\" fits calf 10...   \n",
       "\n",
       "                                         description  price  \\\n",
       "0                                                 []   None   \n",
       "1                                                 []   None   \n",
       "2                                                 []   None   \n",
       "3  [Slip on the Women's Mento and you're ready to...  29.81   \n",
       "4  [Ronnox Calf Sleeves - Allowing Your Body to P...  17.99   \n",
       "\n",
       "                                              images  \\\n",
       "0  {'hi_res': ['https://m.media-amazon.com/images...   \n",
       "1  {'hi_res': ['https://m.media-amazon.com/images...   \n",
       "2  {'hi_res': ['https://m.media-amazon.com/images...   \n",
       "3  {'hi_res': ['https://m.media-amazon.com/images...   \n",
       "4  {'hi_res': ['https://m.media-amazon.com/images...   \n",
       "\n",
       "                                              videos               store  \\\n",
       "0            {'title': [], 'url': [], 'user_id': []}            GiveGift   \n",
       "1            {'title': [], 'url': [], 'user_id': []}              DouBCQ   \n",
       "2            {'title': [], 'url': [], 'user_id': []}  Pastel by Vivienne   \n",
       "3            {'title': [], 'url': [], 'user_id': []}          Guy Harvey   \n",
       "4  {'title': ['HONEST Review: RONNOX Women's 3-Pa...              RONNOX   \n",
       "\n",
       "  categories                                            details parent_asin  \\\n",
       "0         []  {\"Package Dimensions\": \"10.31 x 8.5 x 1.73 inc...  B08BHN9PK5   \n",
       "1         []  {\"Package Dimensions\": \"15 x 10.2 x 0.4 inches...  B08R39MRDW   \n",
       "2         []  {\"Is Discontinued By Manufacturer\": \"No\", \"Pac...  B077KJHCJ4   \n",
       "3         []  {\"Package Dimensions\": \"11.22 x 4.72 x 4.33 in...  B0811M2JG9   \n",
       "4         []  {\"Is Discontinued By Manufacturer\": \"No\", \"Pac...  B07SB2892S   \n",
       "\n",
       "  bought_together subtitle author  \n",
       "0            None     None   None  \n",
       "1            None     None   None  \n",
       "2            None     None   None  \n",
       "3            None     None   None  \n",
       "4            None     None   None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8841484-0835-4732-97fe-86868a1526c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Pretty locket</td>\n",
       "      <td>I think this locket is really pretty. The insi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00LOPVX74</td>\n",
       "      <td>B00LOPVX74</td>\n",
       "      <td>AGBFYI2DDIKXC5Y4FARTYDTQBMFQ</td>\n",
       "      <td>1578528394489</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Great</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07B4JXK8D</td>\n",
       "      <td>B07B4JXK8D</td>\n",
       "      <td>AFQLNQNQYFWQZPJQZS6V3NZU4QBQ</td>\n",
       "      <td>1608426246701</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>One of the stones fell out within the first 2 ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B007ZSEQ4Q</td>\n",
       "      <td>B007ZSEQ4Q</td>\n",
       "      <td>AHITBJSS7KYUBVZPX7M2WJCOIVKQ</td>\n",
       "      <td>1432344828000</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Won’t buy again</td>\n",
       "      <td>Crappy socks. Money wasted. Bought to wear wit...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07F2BTFS9</td>\n",
       "      <td>B07F2BTFS9</td>\n",
       "      <td>AFVNEEPDEIH5SPUN5BWC6NKL3WNQ</td>\n",
       "      <td>1546289847095</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I LOVE these glasses</td>\n",
       "      <td>I LOVE these glasses!  They fit perfectly over...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00PKRFU4O</td>\n",
       "      <td>B00XESJTDE</td>\n",
       "      <td>AHSPLDNW5OOUK2PLH7GXLACFBZNQ</td>\n",
       "      <td>1439476166000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                 title  \\\n",
       "0     5.0         Pretty locket   \n",
       "1     5.0                     A   \n",
       "2     2.0             Two Stars   \n",
       "3     1.0       Won’t buy again   \n",
       "4     5.0  I LOVE these glasses   \n",
       "\n",
       "                                                text images        asin  \\\n",
       "0  I think this locket is really pretty. The insi...     []  B00LOPVX74   \n",
       "1                                              Great     []  B07B4JXK8D   \n",
       "2  One of the stones fell out within the first 2 ...     []  B007ZSEQ4Q   \n",
       "3  Crappy socks. Money wasted. Bought to wear wit...     []  B07F2BTFS9   \n",
       "4  I LOVE these glasses!  They fit perfectly over...     []  B00PKRFU4O   \n",
       "\n",
       "  parent_asin                       user_id      timestamp  helpful_vote  \\\n",
       "0  B00LOPVX74  AGBFYI2DDIKXC5Y4FARTYDTQBMFQ  1578528394489             3   \n",
       "1  B07B4JXK8D  AFQLNQNQYFWQZPJQZS6V3NZU4QBQ  1608426246701             0   \n",
       "2  B007ZSEQ4Q  AHITBJSS7KYUBVZPX7M2WJCOIVKQ  1432344828000             3   \n",
       "3  B07F2BTFS9  AFVNEEPDEIH5SPUN5BWC6NKL3WNQ  1546289847095             2   \n",
       "4  B00XESJTDE  AHSPLDNW5OOUK2PLH7GXLACFBZNQ  1439476166000             0   \n",
       "\n",
       "   verified_purchase  \n",
       "0               True  \n",
       "1               True  \n",
       "2               True  \n",
       "3               True  \n",
       "4               True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c76e7b6e-b38f-4d12-baf1-16a8e3993e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 826108 entries, 0 to 826107\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   main_category    826108 non-null  object \n",
      " 1   title            826108 non-null  object \n",
      " 2   average_rating   826108 non-null  float64\n",
      " 3   rating_number    826108 non-null  int64  \n",
      " 4   features         826108 non-null  object \n",
      " 5   description      826108 non-null  object \n",
      " 6   price            826108 non-null  object \n",
      " 7   images           826108 non-null  object \n",
      " 8   videos           826108 non-null  object \n",
      " 9   store            799270 non-null  object \n",
      " 10  categories       826108 non-null  object \n",
      " 11  details          826108 non-null  object \n",
      " 12  parent_asin      826108 non-null  object \n",
      " 13  bought_together  0 non-null       object \n",
      " 14  subtitle         0 non-null       object \n",
      " 15  author           0 non-null       object \n",
      "dtypes: float64(1), int64(1), object(14)\n",
      "memory usage: 100.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a809c899-572b-4ccf-a1bb-07f9d34dd7c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['{\"Package Dimensions\": \"10.31 x 8.5 x 1.73 inches; 14.82 Ounces\", \"Item model number\": \"DHES5PM21DH12\", \"Date First Available\": \"February 12, 2021\"}',\n",
       "       '{\"Package Dimensions\": \"15 x 10.2 x 0.4 inches; 9.59 Ounces\", \"Item model number\": \"Drop Crotch\", \"Date First Available\": \"February 5, 2021\"}',\n",
       "       '{\"Is Discontinued By Manufacturer\": \"No\", \"Package Dimensions\": \"8.98 x 7.95 x 0.98 inches; 6.24 Ounces\", \"Item model number\": \"RJ-K140NA-LRG\", \"Date First Available\": \"November 11, 2018\"}',\n",
       "       ...,\n",
       "       '{\"Package Dimensions\": \"12 x 8 x 1 inches\", \"Item model number\": \"00_Q14CK581_NL\", \"Date First Available\": \"June 24, 2015\"}',\n",
       "       '{\"Product Dimensions\": \"6 x 6 x 0.5 inches; 0.35 Ounces\", \"Item model number\": \"USAL523141448\", \"Date First Available\": \"July 13, 2016\"}',\n",
       "       '{\"Package Dimensions\": \"3.54 x 2.76 x 0.39 inches; 1.06 Ounces\", \"Item model number\": \"SCXL-HD02\", \"Date First Available\": \"June 1, 2020\"}'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata.details.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2f7ac2-7fc4-4cca-a8af-1de3bc18a403",
   "metadata": {},
   "source": [
    "# Item metadata : Pre-process and Load in BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c147b475-3753-4ece-b838-d14d44ce7f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 826108 rows into test-project-457116.poc_data.amazon_fashion_item_metadata.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Imports ---\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from typing import List, Any, Optional\n",
    "\n",
    "# ---------------------------\n",
    "# Helper converters / cleaners\n",
    "# ---------------------------\n",
    "\n",
    "def _is_nullish(x: Any) -> bool:\n",
    "    return x is None or (isinstance(x, float) and np.isnan(x))\n",
    "\n",
    "def to_str_or_none(x: Any) -> Optional[str]:\n",
    "    if _is_nullish(x):\n",
    "        return None\n",
    "    try:\n",
    "        s = str(x).strip()\n",
    "        return s if s != \"\" else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "_price_num_regex = re.compile(r\"[-+]?\\d*\\.?\\d+\")\n",
    "\n",
    "def to_float_price(x: Any) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Accepts float, int, or strings like '$12.99', '12,345.67', '12.99 - 19.99'\n",
    "    Returns first numeric found, else None.\n",
    "    \"\"\"\n",
    "    if _is_nullish(x):\n",
    "        return None\n",
    "    if isinstance(x, (int, float)) and not isinstance(x, bool):\n",
    "        try:\n",
    "            return float(x) if not np.isnan(x) else None\n",
    "        except Exception:\n",
    "            return None\n",
    "    if isinstance(x, str):\n",
    "        s = x.strip().replace(\",\", \"\")\n",
    "        m = _price_num_regex.search(s)\n",
    "        if m:\n",
    "            try:\n",
    "                return float(m.group(0))\n",
    "            except Exception:\n",
    "                return None\n",
    "        return None\n",
    "    try:\n",
    "        return to_float_price(str(x))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def to_int_or_none(x: Any) -> Optional[int]:\n",
    "    if _is_nullish(x):\n",
    "        return None\n",
    "    try:\n",
    "        return int(float(x))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def to_list_of_str_or_none(x: Any) -> Optional[List[str]]:\n",
    "    \"\"\"\n",
    "    Coerces value to a list of strings.\n",
    "    - Flattens one level if nested lists.\n",
    "    - Drops nullish and empty strings.\n",
    "    \"\"\"\n",
    "    if _is_nullish(x):\n",
    "        return None\n",
    "\n",
    "    out = []\n",
    "    def _append_str(v):\n",
    "        s = to_str_or_none(v)\n",
    "        if s is not None:\n",
    "            out.append(s)\n",
    "\n",
    "    if isinstance(x, list):\n",
    "        for v in x:\n",
    "            if isinstance(v, list):\n",
    "                for vv in v:\n",
    "                    _append_str(vv)\n",
    "            else:\n",
    "                _append_str(v)\n",
    "    elif isinstance(x, str):\n",
    "        s = x.strip()\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            try:\n",
    "                parsed = json.loads(s)\n",
    "                return to_list_of_str_or_none(parsed)\n",
    "            except Exception:\n",
    "                pass\n",
    "        _append_str(s)\n",
    "    else:\n",
    "        _append_str(x)\n",
    "\n",
    "    return out or None\n",
    "\n",
    "def to_json_str_or_none(x: Any) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Produces a JSON string for complex fields; returns None for nullish.\n",
    "    Accepts dict/list/JSON-string; validates when possible.\n",
    "    \"\"\"\n",
    "    if _is_nullish(x):\n",
    "        return None\n",
    "    if isinstance(x, (dict, list)):\n",
    "        try:\n",
    "            s = json.dumps(x, ensure_ascii=False)\n",
    "            return s if s != \"\" else None\n",
    "        except Exception:\n",
    "            return None\n",
    "    if isinstance(x, str):\n",
    "        s = x.strip()\n",
    "        if s == \"\":\n",
    "            return None\n",
    "        if (s.startswith(\"{\") and s.endswith(\"}\")) or (s.startswith(\"[\") and s.endswith(\"]\")):\n",
    "            try:\n",
    "                _ = json.loads(s)  # validate\n",
    "                return s\n",
    "            except Exception:\n",
    "                # fall back to wrapping as a JSON string\n",
    "                return json.dumps(s, ensure_ascii=False)\n",
    "        # wrap arbitrary string as JSON string\n",
    "        return json.dumps(s, ensure_ascii=False)\n",
    "    try:\n",
    "        return json.dumps(str(x), ensure_ascii=False)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ---------------------------\n",
    "# Main transformer + loader\n",
    "# ---------------------------\n",
    "\n",
    "def prepare_item_metadata_dataframe(\n",
    "    df_meta: pd.DataFrame,\n",
    "    ignore_columns: Optional[List[str]] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a new DataFrame with columns coerced to the target BigQuery schema.\n",
    "    \"\"\"\n",
    "    if ignore_columns is None:\n",
    "        ignore_columns = [\"bought_together\", \"subtitle\", \"author\"]\n",
    "\n",
    "    df = df_meta.copy()\n",
    "\n",
    "    # Drop ignored columns if present\n",
    "    to_drop = [c for c in ignore_columns if c in df.columns]\n",
    "    if to_drop:\n",
    "        df = df.drop(columns=to_drop)\n",
    "\n",
    "    # Ensure expected columns exist\n",
    "    expected_cols = [\n",
    "        \"main_category\",\"title\",\"average_rating\",\"rating_number\",\"features\",\"description\",\n",
    "        \"price\",\"images\",\"videos\",\"store\",\"categories\",\"details\",\"parent_asin\"\n",
    "    ]\n",
    "    for c in expected_cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = None\n",
    "\n",
    "    # Coercions\n",
    "    df[\"main_category\"]  = df[\"main_category\"].map(to_str_or_none)\n",
    "    df[\"title\"]          = df[\"title\"].map(to_str_or_none)\n",
    "    df[\"average_rating\"] = df[\"average_rating\"].map(lambda x: None if _is_nullish(x) else float(x))\n",
    "    df[\"rating_number\"]  = df[\"rating_number\"].map(to_int_or_none)\n",
    "\n",
    "    df[\"features\"]    = df[\"features\"].map(to_list_of_str_or_none)\n",
    "    df[\"description\"] = df[\"description\"].map(to_list_of_str_or_none)\n",
    "\n",
    "    df[\"price\"] = df[\"price\"].map(to_float_price)\n",
    "\n",
    "    # Serialize complex/nested as JSON *strings*\n",
    "    df[\"images\"]  = df[\"images\"].map(to_json_str_or_none)\n",
    "    df[\"videos\"]  = df[\"videos\"].map(to_json_str_or_none)\n",
    "    df[\"details\"] = df[\"details\"].map(to_json_str_or_none)\n",
    "\n",
    "    df[\"store\"]        = df[\"store\"].map(to_str_or_none)\n",
    "    df[\"categories\"]   = df[\"categories\"].map(to_list_of_str_or_none)\n",
    "    df[\"parent_asin\"]  = df[\"parent_asin\"].map(to_str_or_none)\n",
    "\n",
    "    # Ensure arrays are lists\n",
    "    for col in [\"features\", \"description\", \"categories\"]:\n",
    "        df[col] = df[col].map(lambda v: list(v) if isinstance(v, (list, tuple)) else (None if v is None else [str(v)]))\n",
    "\n",
    "    # Final column order\n",
    "    df = df[expected_cols]\n",
    "    return df\n",
    "\n",
    "def bq_item_metadata_schema() -> List[bigquery.SchemaField]:\n",
    "    \"\"\"\n",
    "    BigQuery schema aligned with the source spec, but using STRING for complex fields.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        bigquery.SchemaField(\"main_category\",   \"STRING\"),\n",
    "        bigquery.SchemaField(\"title\",           \"STRING\"),\n",
    "        bigquery.SchemaField(\"average_rating\",  \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"rating_number\",   \"INT64\"),\n",
    "        bigquery.SchemaField(\"features\",        \"STRING\", mode=\"REPEATED\"),\n",
    "        bigquery.SchemaField(\"description\",     \"STRING\", mode=\"REPEATED\"),\n",
    "        bigquery.SchemaField(\"price\",           \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"images\",          \"STRING\"),  # JSON as STRING\n",
    "        bigquery.SchemaField(\"videos\",          \"STRING\"),  # JSON as STRING\n",
    "        bigquery.SchemaField(\"store\",           \"STRING\"),\n",
    "        bigquery.SchemaField(\"categories\",      \"STRING\", mode=\"REPEATED\"),\n",
    "        bigquery.SchemaField(\"details\",         \"STRING\"),  # JSON as STRING\n",
    "        bigquery.SchemaField(\"parent_asin\",     \"STRING\"),\n",
    "    ]\n",
    "\n",
    "def load_item_metadata_to_bq(\n",
    "    df_meta: pd.DataFrame,\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    table_id: str,\n",
    "    write_disposition: str = \"WRITE_TRUNCATE\",\n",
    "    ignore_columns: Optional[List[str]] = None,\n",
    "    create_dataset_if_needed: bool = True,\n",
    "    dataset_location: Optional[str] = None,  # e.g., \"northamerica-northeast1\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Transforms and loads item metadata DataFrame to BigQuery.\n",
    "    \"\"\"\n",
    "    client = bigquery.Client(project=project_id)\n",
    "\n",
    "    # Prepare dataframe\n",
    "    df_ready = prepare_item_metadata_dataframe(df_meta, ignore_columns)\n",
    "\n",
    "    # Create dataset if needed\n",
    "    if create_dataset_if_needed:\n",
    "        ds_ref = bigquery.Dataset(f\"{project_id}.{dataset_id}\")\n",
    "        try:\n",
    "            client.get_dataset(ds_ref)\n",
    "        except Exception:\n",
    "            if dataset_location:\n",
    "                ds_ref.location = dataset_location\n",
    "            # else let API decide default location\n",
    "            client.create_dataset(ds_ref, exists_ok=True)\n",
    "\n",
    "    # Define schema\n",
    "    schema = bq_item_metadata_schema()\n",
    "\n",
    "    # Load job config\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        schema=schema,\n",
    "        write_disposition=write_disposition,\n",
    "    )\n",
    "\n",
    "    table_fqdn = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "    load_job = client.load_table_from_dataframe(\n",
    "        df_ready, table_fqdn, job_config=job_config\n",
    "    )\n",
    "    result = load_job.result()  # Waits for job to complete\n",
    "\n",
    "    table = client.get_table(table_fqdn)\n",
    "    print(f\"Loaded {table.num_rows} rows into {table_fqdn}.\")\n",
    "    return table\n",
    "\n",
    "\n",
    "# -------------\n",
    "# Usage:\n",
    "# -------------\n",
    "\n",
    "PROJECT_ID = \"test-project-457116\"\n",
    "DATASET_ID = \"poc_data\"\n",
    "METADATA_TABLE_ID = \"amazon_fashion_item_metadata\"\n",
    "\n",
    "table = load_item_metadata_to_bq(\n",
    "    df_meta=df_metadata,\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    table_id=METADATA_TABLE_ID,\n",
    "    write_disposition=\"WRITE_TRUNCATE\",\n",
    "    ignore_columns=[\"bought_together\", \"subtitle\", \"author\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e567ff1-dfee-44e2-8d54-cba2a5824b47",
   "metadata": {},
   "source": [
    "# Item metadata : Pre-process and Load in BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d5196-71a5-4073-8047-a27c4a264cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2500939 rows into test-project-457116.poc_data.amazon_fashion_reviews_metadata.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "from typing import List, Any, Optional\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers (unchanged)\n",
    "# ---------------------------\n",
    "\n",
    "def _is_nullish(x: Any) -> bool:\n",
    "    return x is None or (isinstance(x, float) and np.isnan(x))\n",
    "\n",
    "def to_str_or_none(x: Any) -> Optional[str]:\n",
    "    if _is_nullish(x):\n",
    "        return None\n",
    "    try:\n",
    "        s = str(x).strip()\n",
    "        return s if s != \"\" else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def to_float_or_none(x: Any) -> Optional[float]:\n",
    "    if _is_nullish(x):\n",
    "        return None\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        try:\n",
    "            return float(str(x))\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "def to_int_or_none(x: Any) -> Optional[int]:\n",
    "    if _is_nullish(x):\n",
    "        return None\n",
    "    try:\n",
    "        return int(float(x))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def to_bool_or_none(x: Any) -> Optional[bool]:\n",
    "    if _is_nullish(x):\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, (int, float)) and not isinstance(x, bool):\n",
    "        return bool(int(x))\n",
    "    if isinstance(x, str):\n",
    "        s = x.strip().lower()\n",
    "        if s in {\"true\",\"t\",\"yes\",\"y\",\"1\"}: return True\n",
    "        if s in {\"false\",\"f\",\"no\",\"n\",\"0\"}: return False\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def to_json_str_or_none(x: Any) -> Optional[str]:\n",
    "    if _is_nullish(x):\n",
    "        return None\n",
    "    if isinstance(x, (dict, list)):\n",
    "        try:\n",
    "            s = json.dumps(x, ensure_ascii=False)\n",
    "            return s if s != \"\" else None\n",
    "        except Exception:\n",
    "            return None\n",
    "    if isinstance(x, str):\n",
    "        s = x.strip()\n",
    "        if s == \"\":\n",
    "            return None\n",
    "        if (s.startswith(\"{\") and s.endswith(\"}\")) or (s.startswith(\"[\") and s.endswith(\"]\")):\n",
    "            try:\n",
    "                _ = json.loads(s)  # validate\n",
    "                return s\n",
    "            except Exception:\n",
    "                return json.dumps(s, ensure_ascii=False)\n",
    "        return json.dumps(s, ensure_ascii=False)\n",
    "    try:\n",
    "        return json.dumps(str(x), ensure_ascii=False)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ---------------------------\n",
    "# Transformer\n",
    "# ---------------------------\n",
    "\n",
    "def prepare_reviews_dataframe(\n",
    "    df_reviews: pd.DataFrame,\n",
    "    ignore_columns: Optional[List[str]] = None,\n",
    "    add_timestamp_column: bool = True,\n",
    "    timestamp_col_name: str = \"review_timestamp\",\n",
    "    timestamp_unit: str = \"s\",  # 's' for seconds, 'ms' for milliseconds\n",
    ") -> pd.DataFrame:\n",
    "    if ignore_columns is None:\n",
    "        ignore_columns = []\n",
    "\n",
    "    df = df_reviews.copy()\n",
    "\n",
    "    # Drop ignored columns if present\n",
    "    to_drop = [c for c in ignore_columns if c in df.columns]\n",
    "    if to_drop:\n",
    "        df = df.drop(columns=to_drop)\n",
    "\n",
    "    expected_cols = [\n",
    "        \"rating\",\"title\",\"text\",\"images\",\"asin\",\"parent_asin\",\n",
    "        \"user_id\",\"timestamp\",\"verified_purchase\",\"helpful_vote\"\n",
    "    ]\n",
    "    for c in expected_cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = None\n",
    "\n",
    "    # Coercions\n",
    "    df[\"rating\"]            = df[\"rating\"].map(to_float_or_none)\n",
    "    df[\"title\"]             = df[\"title\"].map(to_str_or_none)\n",
    "    df[\"text\"]              = df[\"text\"].map(to_str_or_none)\n",
    "    df[\"images\"]            = df[\"images\"].map(to_json_str_or_none)  # JSON as STRING\n",
    "    df[\"asin\"]              = df[\"asin\"].map(to_str_or_none)\n",
    "    df[\"parent_asin\"]       = df[\"parent_asin\"].map(to_str_or_none)\n",
    "    df[\"user_id\"]           = df[\"user_id\"].map(to_str_or_none)\n",
    "    df[\"timestamp\"]         = df[\"timestamp\"].map(to_int_or_none)    # keep INT64 in BQ\n",
    "    df[\"verified_purchase\"] = df[\"verified_purchase\"].map(to_bool_or_none)\n",
    "    df[\"helpful_vote\"]      = df[\"helpful_vote\"].map(to_int_or_none)\n",
    "\n",
    "    # Derived TIMESTAMP column (UTC) for convenience/partitioning\n",
    "    if add_timestamp_column:\n",
    "        ts_series = pd.to_datetime(\n",
    "            df[\"timestamp\"], \n",
    "            unit=timestamp_unit, \n",
    "            utc=True, \n",
    "            errors=\"coerce\"\n",
    "        )\n",
    "        # pandas dtype: datetime64[ns, UTC] -> BQ TIMESTAMP\n",
    "        df[timestamp_col_name] = ts_series\n",
    "\n",
    "    # Final column order\n",
    "    final_cols = [\n",
    "        \"rating\",\"title\",\"text\",\"images\",\"asin\",\"parent_asin\",\n",
    "        \"user_id\",\"timestamp\",\"verified_purchase\",\"helpful_vote\"\n",
    "    ]\n",
    "    if add_timestamp_column:\n",
    "        final_cols.append(timestamp_col_name)\n",
    "\n",
    "    df = df[final_cols]\n",
    "    return df\n",
    "\n",
    "def bq_reviews_schema(\n",
    "    add_timestamp_column: bool = True,\n",
    "    timestamp_col_name: str = \"review_timestamp\",\n",
    "):\n",
    "    schema = [\n",
    "        bigquery.SchemaField(\"rating\",            \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"title\",             \"STRING\"),\n",
    "        bigquery.SchemaField(\"text\",              \"STRING\"),\n",
    "        bigquery.SchemaField(\"images\",            \"STRING\"),  # JSON as STRING\n",
    "        bigquery.SchemaField(\"asin\",              \"STRING\"),\n",
    "        bigquery.SchemaField(\"parent_asin\",       \"STRING\"),\n",
    "        bigquery.SchemaField(\"user_id\",           \"STRING\"),\n",
    "        bigquery.SchemaField(\"timestamp\",         \"INT64\"),   # unix epoch\n",
    "        bigquery.SchemaField(\"verified_purchase\", \"BOOL\"),\n",
    "        bigquery.SchemaField(\"helpful_vote\",      \"INT64\"),\n",
    "    ]\n",
    "    if add_timestamp_column:\n",
    "        schema.append(bigquery.SchemaField(timestamp_col_name, \"TIMESTAMP\"))\n",
    "    return schema\n",
    "\n",
    "# ---------------------------\n",
    "# Loader (fixed chunk logic)\n",
    "# ---------------------------\n",
    "\n",
    "def load_reviews_to_bq(\n",
    "    df_reviews: pd.DataFrame,\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    table_id: str,\n",
    "    write_disposition: str = \"WRITE_TRUNCATE\",\n",
    "    ignore_columns: Optional[List[str]] = None,\n",
    "    create_dataset_if_needed: bool = True,\n",
    "    dataset_location: Optional[str] = None,  # e.g., \"northamerica-northeast1\"\n",
    "    add_timestamp_column: bool = True,\n",
    "    timestamp_col_name: str = \"review_timestamp\",\n",
    "    timestamp_unit: str = \"s\",  # 's' or 'ms'\n",
    "    time_partitioning_field: Optional[str] = None,  # e.g., \"review_timestamp\"\n",
    "    clustering_fields: Optional[List[str]] = None,  # e.g., [\"parent_asin\"]\n",
    "    batch_rows: Optional[int] = None,\n",
    "):\n",
    "    client = bigquery.Client(project=project_id)\n",
    "\n",
    "    df_ready = prepare_reviews_dataframe(\n",
    "        df_reviews=df_reviews,\n",
    "        ignore_columns=ignore_columns,\n",
    "        add_timestamp_column=add_timestamp_column,\n",
    "        timestamp_col_name=timestamp_col_name,\n",
    "        timestamp_unit=timestamp_unit,\n",
    "    )\n",
    "\n",
    "    # Create dataset if needed\n",
    "    if create_dataset_if_needed:\n",
    "        ds_ref = bigquery.Dataset(f\"{project_id}.{dataset_id}\")\n",
    "        try:\n",
    "            client.get_dataset(ds_ref)\n",
    "        except Exception:\n",
    "            if dataset_location:\n",
    "                ds_ref.location = dataset_location\n",
    "            client.create_dataset(ds_ref, exists_ok=True)\n",
    "\n",
    "    # Base job config\n",
    "    base_job_config = bigquery.LoadJobConfig(\n",
    "        schema=bq_reviews_schema(\n",
    "            add_timestamp_column=add_timestamp_column,\n",
    "            timestamp_col_name=timestamp_col_name,\n",
    "        ),\n",
    "        write_disposition=write_disposition,\n",
    "    )\n",
    "    if time_partitioning_field:\n",
    "        base_job_config.time_partitioning = bigquery.TimePartitioning(\n",
    "            type_=bigquery.TimePartitioningType.DAY,\n",
    "            field=time_partitioning_field,\n",
    "        )\n",
    "    if clustering_fields:\n",
    "        base_job_config.clustering_fields = clustering_fields\n",
    "\n",
    "    table_fqdn = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "\n",
    "    def _load_chunk(chunk_df: pd.DataFrame, disposition: str):\n",
    "        # Safe copy of the base config (avoid private attrs)\n",
    "        cfg = copy.copy(base_job_config)\n",
    "        cfg.write_disposition = disposition\n",
    "        load_job = client.load_table_from_dataframe(chunk_df, table_fqdn, job_config=cfg)\n",
    "        _ = load_job.result()\n",
    "\n",
    "    # Batch or single load\n",
    "    if batch_rows and batch_rows > 0 and len(df_ready) > batch_rows:\n",
    "        start, end, chunk_idx = 0, len(df_ready), 0\n",
    "        while start < end:\n",
    "            stop = min(start + batch_rows, end)\n",
    "            chunk = df_ready.iloc[start:stop].copy()\n",
    "            disp = write_disposition if chunk_idx == 0 else \"WRITE_APPEND\"\n",
    "            _load_chunk(chunk, disp)\n",
    "            start = stop\n",
    "            chunk_idx += 1\n",
    "    else:\n",
    "        _load_chunk(df_ready, write_disposition)\n",
    "\n",
    "    table = client.get_table(table_fqdn)\n",
    "    print(f\"Loaded {table.num_rows} rows into {table_fqdn}.\")\n",
    "\n",
    "\n",
    "# -------------\n",
    "# Usage:\n",
    "# -------------\n",
    "\n",
    "PROJECT_ID = \"test-project-457116\"\n",
    "DATASET_ID = \"poc_data\"\n",
    "REVIEWS_TABLE_ID = \"amazon_fashion_reviews_metadata\"\n",
    "\n",
    "\n",
    "table = load_reviews_to_bq(\n",
    "    df_reviews=df_reviews,\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    table_id=REVIEWS_TABLE_ID,\n",
    "    write_disposition=\"WRITE_TRUNCATE\",\n",
    "    add_timestamp_column=True,\n",
    "    timestamp_col_name=\"review_timestamp\",\n",
    "    timestamp_unit=\"ms\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m130",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m130"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
